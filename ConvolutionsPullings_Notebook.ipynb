{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course 1 - Part 6 - Lesson 2 - Notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viktoriya-bel/Tensorflow-labs/blob/main/ConvolutionsPullings_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6gHiH-I7uFa"
      },
      "source": [
        "#Повышение точности компьютерного зрения с помощью сверток\n",
        "\n",
        "В предыдущих уроках вы видели, как распознавать вещи, используя глубокую нейронную сеть (DNN), содержащую три слоя - входной слой (в форме данных), выходной слой (в форме желаемого результата) и скрытый слой. Вы экспериментировали, как повлияет изменение размера скрытого слоя, количества эпох обучения и т. д. на конечную точность.\n",
        "\n",
        "Для удобства здесь опять выложен весь тот код. Запустите его и запишите полученную в конце точность теста.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcsRtq9OLorS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a278e19f-a51a-467d-cd81-c117b1a2ebb9"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 4ms/step - loss: 0.5005 - accuracy: 0.8232\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3728 - accuracy: 0.8647\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3361 - accuracy: 0.8768\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3104 - accuracy: 0.8866\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2938 - accuracy: 0.8916\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3659 - accuracy: 0.8694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zldEXSsF8Noz"
      },
      "source": [
        "Ваша точность, вероятно, будет около 89% при обучении и 87% на тестировании. Как ее увеличить? Один из способов - использовать то, что называется Convolutions. \n",
        "Если вы когда-либо выполняли обработку изображений с использованием фильтра (например, https://en.wikipedia.org/wiki/Kernel_(image_processing)), то свертки будут выглядеть очень знакомо.\n",
        "\n",
        "Запустите приведенный ниже код - это та же нейронная сеть, что и раньше, но на этот раз сначала добавляются сверточные слои. Это займет больше времени, но посмотрите на точность:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0tFgT1MMKi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb617a3-dc80-4e5d-8832-d8cdd66dbe3e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64,  (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 4ms/step - loss: 0.4393 - accuracy: 0.8401\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2962 - accuracy: 0.8914\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2508 - accuracy: 0.9067\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2165 - accuracy: 0.9194\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1907 - accuracy: 0.9287\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2574 - accuracy: 0.9045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRLfZ0jt-fQI"
      },
      "source": [
        "Вероятно, он вырос до 93% по данным обучения и до 91% по данным проверки.\n",
        "Это шаг в правильном направлении!\n",
        "Попробуйте запустить его для большего количества эпох - скажем, около 20, и изучите результаты. Но хотя результаты могут показаться действительно хорошими, результаты валидации могут на самом деле снизиться из-за того, что называется «переобучением», которое будет обсуждаться позже.\n",
        "(В двух словах, «переобучение» происходит, когда сеть действительно хорошо изучает данные из обучающего набора, но слишком специализируется на этих конкретных данных, и в результате становится менее эффективной на других данных. Например, если всю жизнь Вы видели только красные туфли, то когда вы видите красную обувь, вы очень хорошо ее опознаете, но синие замшевые туфли могут сбить вас с толку.)\n",
        "\n",
        "Затем снова посмотрите на код и, шаг за шагом, посмотрите, как были построены свертки:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaLX5cgI_JDb"
      },
      "source": [
        "Шаг 1 - собрать данные. Вы заметите, что здесь есть небольшое изменение: данные обучения необходимо переформировать. Это связано с тем, что первая свертка ожидает единственный тензор, содержащий сразу все примеры обучения, поэтому вместо 60000 элементов 28x28x1 в списке мы имеем один четырехмерный список размером 60000x28x28x1, и то же самое для тестовых изображений. Если вы этого не сделаете, вы получите ошибку при обучении, поскольку Convolutions не поймут другую форму.\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS_W_INc_kJQ"
      },
      "source": [
        "Далее следует определить вашу модель. Теперь вместо входного слоя вверху вы добавите Convolution. Параметры:\n",
        "\n",
        "1. Количество сверток, которые вы хотите сгенерировать. Чисто произвольно, но хорошо начать с чего-то порядка 32\n",
        "2. Размер свертки, в данном случае 3х3\n",
        "3. Используемая функция активации - здесь мы будем использовать функцию relu, которая, как вы помните, возвращает x при x > 0, в противном случае возвращает 0\n",
        "4. Форма входных данных на первом слое.\n",
        "\n",
        "За Convolution следует слой MaxPooling, который предназначен для сжатия изображений, с сохранением признаков, которые были выделены в результате сверток. Задав (2,2) для MaxPooling, вы получите уменьшение размера изображения в четыре раза. Не вдаваясь в подробности, идея состоит в том, что пуллинг создает 2х2 массив пикселей и выбирает из них один с самым большим значением, превращая 4 пикселя в 1. Он повторяет это по всему изображению, уменьшая изображение в 4 раза.\n",
        "\n",
        "Вы можете вызвать model.summary(), чтобы увидеть размер и форму сети, и вы заметите, как после каждого слоя MaxPooling уменьшается размер изображения.\n",
        "\n",
        "```\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMorM6daADjA"
      },
      "source": [
        "Добавляем еще одну свертку\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1-x-kZF4_tC"
      },
      "source": [
        "Теперь надо \"распластать\" результат. После этого вы будете иметь такую же структуру данных, как и в версии нейронной сети без сверток, которую мы делали в прошлый раз.\n",
        "\n",
        "```\n",
        "  tf.keras.layers.Flatten(),\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPtqR23uASjX"
      },
      "source": [
        "Те же 128 нейронов в полносвязном слое и 10 нейронов в слое выхода, что и в примере до свертки:\n",
        "\n",
        "\n",
        "```\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0GSsjUhAaSj"
      },
      "source": [
        "Теперь скомпилируйте модель, вызовите метод fit для обучения и оцените loss и accuracy на тестовом наборе.\n",
        "\n",
        "```\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXx_LX3SAlFs"
      },
      "source": [
        "#Визуализация сверток и пуллинга\n",
        "\n",
        "Этот код покажет нам свертки графически. print(test_labels [; 100]) покажет нам первые 100 распознанных меток в тестовом наборе, и вы можете видеть, что нулевая 0, 23-я и 28-я имеют одинаковое значение (9). Это все ботинки. Давайте посмотрим на результат запуска свертки для каждого, и вы начнете видеть как появляются общие черты между ними. Теперь, когда DNN обучается на этих данных, она работает с гораздо меньшими затратами и, возможно, обнаруживает общие признаки между ботинками на основе этой комбинации свертки/пуллинга."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-6nX4QsOku6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6ab9a5-6f2d-4d23-9775-1391fc421312"
      },
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FGsHhv6JvDx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "81afaf71-0714-4ab1-8888-aa9c23436744"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, axarr = plt.subplots(3,4)\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=23\n",
        "THIRD_IMAGE=28\n",
        "CONVOLUTION_NUMBER = 1\n",
        "from tensorflow.keras import models\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "for x in range(0,4):\n",
        "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[0,x].grid(False)\n",
        "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[1,x].grid(False)\n",
        "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[2,x].grid(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 139ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD7CAYAAAC2a1UBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaSUlEQVR4nO3db8xdZZnv8e+vBZwEmAmVsdO0lcKkMakmDISpMhBPtWAKEktOTph2oukLksaoE4gmTvEkmkxiUn1h9Hg8wWZsWqNiOyLSkCJ2KoSYOB1KpwxtEVubEtqUPsNooPKG03LNi7V22d3sP2vvvf7u9fskT/bea6+n69pXn33da91rrftWRGBmZvUyr+oAzMzsnVyczcxqyMXZzKyGXJzNzGrIxdnMrIZcnM3Mamiq4ixpjaQXJR2TtCmvoMzM2m7i4ixpPvAd4A5gBbBe0oq8AjM3fmZtdskUv7sSOBYRxwEk/RhYCxwZ9AuS2n7Hy6sR8edZVuxq/G4HTgLPSNoVEX3z69xmzy0kDR/wLWA+8E8RsXnE+q3Ob0SoqH+77bllwN/uNMV5MfBy1+uTwAdH/9r8KTbZdOdfGmPlsRs/5zabcRu+t7U1v+dL2EZbcwuD/nYLPyEoaaOk/ZL2F72tGdOv8VtcUSyz5kLDFxFvAp2Gz6w2pinOp4ClXa+XpMsuEhFbIuKmiLhpim1ZH274Jpap4XN+J+NzJfmYpjg/AyyXdK2ky4B1wK58wjIyNH5u+Irl/I7PFwrkZ+LiHBHngM8BTwAvADsj4nBegZkbvwJlOuqzibjLKCfTnBAkInYDu3OKxbpExDlJncZvPrDVjV9uLjR8JEV5HfB31YY0Mya8UMB6TVWcrVhu/Irhhq96kjYCG6uOo85cnK2V3PAVJvOFAsAW8HXOg3hsDTPLk8+V5MR7zmaWG3cZ5cfF2cxy5S6jfLhbw8yshrznbGaWk0+/57Nj/86Dc/+n73LvOZuZ1ZCLs5lZDbk4m5nVkPuczWZcv37QB+e+U0EkNg7vOZuZ1ZCLs5lZDbk4m5nVkIuzmVkNuTibmdXQyKs1JG0F7gLmIuID6bIFwA5gGXACuCci/lBcmGY2yi9W/s++yz/6ryvfsezBeb5ao+6y7DlvA9b0LNsE7I2I5cDe9LXlTNIJSc9LOuhJRs3aZWRxjoingd/3LF4LbE+fbwfuzjkue9tHIuKvPMmoWbtMehPKwog4nT5/BVg4aEVPR2NmTTSom2iYfl1Iozw4YBd56hOCERHAwGlmPL38VAL4haRn00buIpI2StrvLg+z2TPpnvMZSYsi4rSkRcBcnkHZBbdGxClJ7wH2SPpN2s0EeB42s1k2aXHeBWwANqePj+YWkV0QEafSxzlJjwArgaeH/5ZlIekEcBY4D5ybhSO7j/3bT/u/MW/A8gJIWgp8n6SrM4AtEfGt0gKYISO7NSQ9BPwaeJ+kk5LuJSnKt0s6CtyWvrYcSbpc0pWd58DHgEPVRjVzfLI1f+eAL0TECuBDwGclrag4pkYaueccEesHvLU651jsYguBRyRB8v/0o4j4ebUhmQ2XXihwOn1+VtILwGLgSKWBNZCHDK2piDgOXF91HDOsc7I1gO+m/fcX8ZVG05G0DLgB2NfnPed2BBdna6uhJ1vBJ1ynIekK4GHg/oh4vfd953Y0j61hrdR9shXonGy1HEi6lKQw/zAiyjsbOWNcnK11fLK1OEpOknwPeCEivlF1PE3mbg1rI59sLc4twKeA5yUdTJd9KSJ2VxhTI7k4W+v4ZGtxIuJXgKqOYxa4OJuZ9THwpp5hcrzhx33OZmY15OJsZlZDLs5mZjXk4mxmVkMuzmZmNeTibGZWQy7OZmY15OJsZlZDWQbbXyrpSUlHJB2WdF+6fIGkPZKOpo9XFR+umVk7ZNlzHjSzwSZgb0QsB/amr83MLAcji3NEnI6IA+nzs0BnZoO1wPZ0te3A3UUFOcskbZU0J+lQ1zIflZi13Fh9zj0zGyxMp6QBeIVkpC8b3zZgTc8yH5WYtVzm4jxsZoOICJJpf/r93kZJ+yXtnyrSGZXOvvH7nsU+KjFruUzFecDMBmckLUrfXwTM9fvdiNgSETd5huOxZDoqccNnNruyXK0xaGaDXcCG9PkG4NH8w7NhRyVu+MxmV5Y9587MBh+VdDD9uRPYDNwu6ShwW/ra8pHpqMTMZtfIwfZHzGywOt9wLNU5KtmMj0qsgSTNB/YDpyLirqrjaSLfIVgxSQ8BvwbeJ+mkpHvxUYk1330kl93ahDxNVcUiYv2At3xUYo0kaQnwceCrwOcrDqexvOdsM8s3+FTmm8AXgbcGreArjUZzcbZZtg3f4FMqSXcBcxHx7LD1fKXRaC7ONrN8g08lbgE+IekE8GOSq7x+UG1IzeTibG2TedgBH3qPLyIeiIglEbEMWAf8MiI+WXFYjeQTgtZaERGS+t7gk76/BdgCMGw9syJ4z9naxjf4lCQinvI1zpMre8/5VTj/RvLYaFcz2We4Ju9AurwK519Kn08aX52M+xmy5nbSG3w6+Z2F3GbV+axF/t3CxX+7/bZflbK23ze/SoZuKI+k/U0/Q1v3z1D3+LLI4zOkN/isIvmSnQG+AvwM2Am8F3gJuCciek8aFhpXU1T9Wdu+ffc528zyDT7WZO5zNjOroSqK85YKtpm3un+GuseXRV0/Q13jKkLVn7XV2y+9z9nMzEZzt4aZWQ25OJuZ1VCpxVnSGkkvSjomqREDzkhaKulJSUckHZZ0X7q8dqObNTG/0JzR45qa31Gqzv+ovEp6l6Qd6fv7JC3Lcdt9v98966yS9FrXTFBfzmv7Q0VEKT/AfOB3wHXAZcBzwIqytj9F3IuAG9PnVwK/BVYAXwc2pcs3AV+rOM5G5jeN/cPAjcChrmXObwvynyWvwGeAB9Pn64AdOW6/7/e7Z51VwGNl/7+Uuee8EjgWEccj4k2SEavWlrj9iUTE6Yg4kD4/SzK7w2LqN7pZI/MLjRk9rrH5HaXi/GfJa3csPwFWpxNPT23I97tyUxXnMQ/zFgMvd70+SU2SkFV6OHUDsI8xRjcrSePz28P5rVZZ+c+S1wvrRMQ54DXg3XkH0vP97nWzpOckPS7p/Xlvu5+Ji3M6geN3gDtIDvPXS1qRV2B1I+kK4GHg/oh4vfu9SI59cr8mcVb7OMdVVH4tmzbkf9j3GzgAXBMR1wPfJhkCoHhT9NXcDDzR9foB4IER60fLf/4zz764nvWr/mxV/2TObZqvNcCLwDHSvtUR61f9+ar+ebGIflVcF4IBf7vTjK3R73Dkg70rSdoIbHx7yfwpNtl0fUfeGuRCXxyApE5f3JHBv+LcZtF11Hc7yd/tM5J2RcSQ3EJ783seso/eN65nkoe25hYG/e0WfkIwPFfYpNrWx1mmmT25V6DNRfyjaR+y9TFNcT4FLO16vSRdZiXxNEoTy9TwOb9vi/GGVfW5khxMU5yfAZZLulbSZSTXH+7KJywjQ+Pno5JiOb/ja9uFAkWauDinhyOfA54guTZwZ0Qcziswc+NXIB/1FcddRjmZarD9iNgN7M4pFusSEeckdRq/+cBWN365udDwkRTldcDfVRvSzJjwQgHr5ZlQasyNXzHc8FUvPLP5SC7O1kpu+ArjLqOceMhQM8uTz5XkxHvOZpYbdxnlx8XZzHLlLqN8uFvDzKyGXJzNzGrIxdnMrIZcnM3MasjF2cyshlyczcxqyMXZzKyGXJzNzGrIxdnMrIZcnM3MasjF2cyshkaOrSFpK3AXMBcRH0iXLQB2AMuAE8A9EfGH4sI0a59zb23vu/ySeRtKjsSqkGXPeRuwpmfZJmBvRCwH9qavLWeSTkh6XtJBTzJq1i4ji3NEPA30zry7Fug069uBu3OOy972kYj4K08yatYukw4ZujAiTqfPXwEWDlrRc4WZWR0M6iYapOruo6lPCEZEAAPnAPP08lMJ4BeSnk0buYtI2ihpv7s8zGbPpHvOZyQtiojTkhYBc3kGZRfcGhGnJL0H2CPpN2k3E+BJMs1m2aTFeRewAdicPj6aW0R2QUScSh/nJD0CrASeHv5bloWkE8BZ4Dxwro5HdlUfVk9C0lLg+yRdnQFsiYhvVRtVM43s1pD0EPBr4H2STkq6l6Qo3y7pKHBb+tpyJOlySVd2ngMfAw5VG9XM8cnW/J0DvhARK4APAZ+VtKLimBpp5J5zRKwf8NbqnGOxiy0EHpEEyf/TjyLi59WGZDZceqHA6fT5WUkvAIuBI5UG1kCe4LWmIuI4cH3VccywzsnWAL6b9t9fxFcaTUfSMuAGYF+f95zbEVycra2GnmwFn3CdhqQrgIeB+yPi9d73ndvRPLaGtVL3yVagc7LVciDpUpLC/MOI+GnV8TSVi7O1jk+2FkfJSZLvAS9ExDeqjqfJ3K1hbeSTrcW5BfgU8Lykg+myL0XE7gpjaiQXZ2sdn2wtTkT8ClDVccwCF2cza4Wm3dTjPmczsxpycTYzqyEXZzOzGnJxNjOrIRdnM7MacnE2M6shF2czsxpycTYzq6GRN6EMmtlA0gJgB7AMOAHcExF/KC5UMwP42z/7TN/lO177fyVHYkXKsuc8aGaDTcDeiFgO7E1f25gkbZU0J+lQ17IFkvZIOpo+XlVljGZWvpHFOSJOR8SB9PlZoDOzwVqgM9f4duDuooKccduANT3L3PCZtdxYfc49MxssTKekAXiFpNvDxpQO8P77nsVu+MxaLvPAR70zG6TDLQIQETFoNgNPRzMRN3xmObvu8jvGWv+vL7l27G3k2e+fqTgPmNngjKRFEXFa0iJgrt/vejqa6bjha69BxcQn/tphZLfGkJkNdgGdMfg2AI/mH15rnUkbPEY1fBFxU0TcVGp0Zla4LH3OnZkNPirpYPpzJ7AZuF3SUeC29LXlww2fNZqk+ZL+XdJjVcfSVCO7NUbMbLA633DaR9JDwCrgakknga+QNHQ7Jd0LvATcU12EZhO5j+TKrj+tOpCm8kwoFYuI9QPecsNnjSRpCfBx4KvA5ysOp7F8+7aZ5e2bwBeBt6oOpMm852wzS9JW4C5gLiI+kC5rzLADx994vOoQxiapk+9nJa0asp6vNBrBe842y7bhuy/LdgvwCUkngB+TXEjwg96VfKXRaC7ONrN892X5IuKBiFgSEcuAdcAvI+KTFYfVSO7WsLbJfPelD72tSi7O1lrD7r5M3/fdrVOIiKeApyoOo7HcrWFtk+nuS7Oqlb3n/CqcfyN5bLSrmewzXJN3IF1ehfMvpc8nja9Oxv0MWXPbuftyM+PdfdnJ7yzkNqvOZy3y7xYu/tvtt/1cHH9jvJsVj5f3f903v4oo92hN0v6mn6Gt+2eoe3xZ5PEZuu++BM6Q3H35M2An8F7Suy8jovekYaFxNUXVn7Xt23efs80s331pTeY+ZzOzGqqiOG+pYJt5q/tnqHt8WdT1M9Q1riJU/Vlbvf3S+5zNzGw0d2uYmdWQi7OZWQ2VWpwlrZH0oqRjkhox4IykpZKelHRE0mFJ96XLF0jaI+lo+nhVDWJtXH4hGT1O0pykQ13LnN+SVJ3/UXmV9C5JO9L390laluO2+36/e9ZZJem1rpmgvpzX9oeKiFJ+gPnA74DrgMuA54AVZW1/irgXATemz68EfgusAL4ObEqXbwK+VnGcjcxvGvuHgRuBQ13LnN8W5D9LXoHPAA+mz9cBO3Lcft/vd886q4DHyv5/KXPPeSVwLCKOR8SbJMMJri1x+xOJiNMRcSB9fpZk6p3F1G90s0bmFxozelxj8ztKxfnPktfuWH4CrE4nnp7akO935aYqzmMe5i0GXu56fZKaJCGr9HDqBmAfY4xuVpLG57eH81utsvKfJa8X1omIc8BrwLvzDqTn+93rZknPSXpc0vvz3nY/ExdnSfOB7wB3kBzmr5e0Iq/A6kbSFcDDwP0R8Xr3e5Ec++R+TeKs9nGOq4j8OrfZFfX3XSfDvt/AAeCaiLge+DbJEADFm6Kv5mbgia7XDwAPjFg/Wv7zn3n2xfWsX/Vnq/qnsNw6vwTwYhH9qrguBAP+dqcZW6Pf4cgHe1d654Dl86fYZNP1HXlrkAt9cQCSOn1xRwb/inOb0QS5hfbm9zxkH71vXM8kD23NLQz62y38hGB4rrBJjeyLk7RR0n5J+0uNrPna1n+ch81F/KNpH7L1MU1xPgUs7Xq9JF1mJXHDVyw3fm+L8YZVdX9+DqYpzs8AyyVdK+kykusPd+UTluHGr0iZcuvGb3xtu1CgSBMX5/Rw5HPAEyTXBu6MiMN5BWZu/Ark3BZnZq8HL9tUg+1HxG5gd06xWJeIOCep0/jNB7a68cuHc1uoCS8UsF6eCaXG3PgVx7mtVnhm85E8Kp2Z5cnnSnLi4mxmeXJ/fk7crWFmuXF/fn5cnM0sV+7Pz4eLs9mMe/Pb77w1+rK/P19BJDYOF2czs5yce2v76JV6XDLvk32X+4SgmVkNuTibmdWQi7OZWQ25z9lsxv3lA//jHcuuu/xdfdc9/sbjRYdjGXnP2cyshlyczcxqyMXZzKyGXJzNzGpoZHGWtFXSnKRDXcsWSNoj6Wj6eFWxYZqZtUuWqzW2Af8X+H7Xsk3A3ojYnM4Rtgn4h/zDM7NpvfzHX1Ydgk1g5J5zRDwN9E7uuBbo3Ke4Hbg757gMkHRC0vOSDnqSUbN2mfQ654URcTp9/gqwMKd47J0+EhGvVh2EmZVr6ptQIiKGTTPjucLMrC0umbcht39r0qs1zkhaBJA+zg1a0dPLTyWAX0h6Nm3kLiJpo6T97vIwmz2TFuddQKeJ2AA8mk841uPWiLgRuAP4rKQPd7/phm9y7s8vhqSlkp6UdETSYUn3VR1TU43s1pD0ELAKuFrSSeArwGZgp6R7gZeAe4oMsq0i4lT6OCfpEWAl8HS1Uc0U9+fn7xzwhYg4IOlK4FlJeyLiSNWBNc3I4hwR6we8tTrnWKyLpMuBeRFxNn3+MeAfKw7LbKj0QoHT6fOzkl4AFgMuzmPyqHT1tRB4RBIk/08/ioifVxvSTOn05wfw3YjYUnVAs0bSMuAGYF+1kTSTi3NNRcRx4Pqq45hht0bEKUnvAfZI+k16Tf8FvtJocpKuAB4G7o+I1/u879yO4LE1rJW6+/OBTn9+7zo+4ToBSZeSFOYfRsRP+63j3I7m4mytI+ny9GQVXf35h4b/lmWhpB/ue8ALEfGNquNpMndrWBu5P784twCfAp6XdDBd9qWI2F1hTI3k4myt4/784kTErwBVHccscLeGmVkNuTibmdWQi7OZWQ25OJuZ1ZCLs5lZDbk4m5nVkIuzmVkNuTibmdWQi7OZWQ25OJuZ1dDI4jxo2hlJCyTtkXQ0fbyq+HDNzNohy55zZ9qZFcCHSOayWwFsAvZGxHJgb/raxiRpq6Q5SYe6lrnhM2u5kcU5Ik5HxIH0+VmgM+3MWmB7utp24O6igpxx24A1Pcvc8Jm13Fh9zj3TzixM5wsDeIVkGMZ+v7NR0n7PcNxfOvvG73sWu+Eza7nMxXnYtDMRESRzsr2DZzyYSKaGz8xmV6biPGDamTOSFqXvLwLmigmx3YY1fD4qMZtdWa7WGDTtzC5gQ/p8A/Bo/uG1VqaGz0clZrMry55zZ9qZj0o6mP7cCWwGbpd0FLgtfW35cMNnjSZpvqR/l/RY1bE01chpqkZMO7M633DaR9JDwCrgakknga+QNHQ7Jd0LvATcU12EZhO5j+TKrj+tOpCm8hyCFYuI9QPecsNnjSRpCfBx4KvA5ysOp7F8+7aZ5e2bwBeBtwat4JPZo3nP2WaWpK3AXcBcRHwgXbYA2AEsA04A90TEH6qKcRLn3tred/kl8zb0XV4mSZ18Pytp1aD1ImILsCX9nb5XI7Wd95xtlm3Dd1+W7RbgE5JOAD8muZDgB9WG1EwuzjazfPdl+SLigYhYEhHLgHXALyPikxWH1Uju1rC2yXz3paSNwMZSojLr4eJsrRURMay/0/2i04mIp4CnKg6jsdytYW3jYQesEcrec34Vzr+RPDba1Uz2Ga7JO5Aur8L5l9Lnk8ZXJ+N+hqy57dx9uZnx7r7s5Lfy3F4yr7Qu3M5nLfLvFi7+2+23/aqUtf2++VUyrk55JO1v+lgQdf8MdY8vizw+Q/fdl8AZkrsvfwbsBN5LevdlRPSeNCw0rqao+rO2ffvuc7aZ5bsvrcnc52xmVkNVFOctFWwzb3X/DHWPL4u6foa6xlWEqj9rq7dfep+zmZmN5m4NM7MaKrU4S1oj6UVJxyQ1YkwDSUslPSnpiKTDku5Lly+QtEfS0fTxqhrE2rj8QjJAkaQ5SYe6ljm/Jak6/6PyKuldknak7+9LJ5rOa9t9v98966yS9FrXZCNfzmv7Q0VEKT/AfOB3wHXAZcBzwIqytj9F3IuAG9PnVwK/BVYAXwc2pcs3AV+rOM5G5jeN/cPAjcChrmXObwvynyWvwGeAB9Pn64AdOW6/7/e7Z51VwGNl/7+Uuee8EjgWEccj4k2SEavWlrj9iUTE6Yg4kD4/SzK7w2LqN4BOI/MLjRmgqLH5HaXi/GfJa3csPwFWp3ObTm3I97tyZRbnxcDLXa9PUpMkZJUeTt0A7GOMAXRK0vj89nB+q1VW/rPk9cI6EXEOeA14d96B9Hy/e90s6TlJj0t6f97b7sc3oWQk6QrgYeD+iHi9u+GOGD6Ajk3H+a1WG/Lf+/3uefsAcE1E/DGd3PpnwPKiYypzz/kUsLTr9ZJ0We1JupTkP+6HEfHTdHHdBtBpbH4HcH6rVVb+s+T1wjqSLgH+DPivvAIY8P2+ICJej4g/ps93A5dKujqv7Q9SZnF+Blgu6VpJl5F07O8qcfsTSfu2vge8EBHf6HqrM4AOjDeATlEamd8hnN9qlZX/LHntjuV/kQzgn8ue/JDvd/c6f9Hp45a0kqRu5tY4DFTm2UfgTpKzob8D/nfZZz8njPlWIID/AA6mP3eS9HntBY4C/wIsqEGsjctvGvdDwGng/5P0Od7r/LYn//3yCvwj8In0+Z8A/wwcA/4NuC7HbQ/6fn8a+HS6zueAwyRXkvwr8Ddl/L/4DkEzsxryHYJmZjXk4mxmVkMuzmZmNeTibGZWQy7OZmY15OJsZlZDLs5mZjXk4mxmVkP/DXCSUaXV83jXAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KVPZqgHo5Ux"
      },
      "source": [
        "##УПРАЖНЕНИЯ\n",
        "\n",
        "1. Попробуйте изменить свертки. Измените 32 на 16 или 64. Как это повлияет на точность и/или время обучения?\n",
        "\n",
        "2. Удалите окончательную свертку. Как это повлияет на точность или время обучения?\n",
        "\n",
        "3. Как насчет добавления большего количества сверток? Как вы думаете, какое влияние это окажет? Экспериментируйте с этим.\n",
        "\n",
        "4. Удалите все свертки, кроме первой. Как вы думаете, какое влияние это окажет? Экспериментируйте с этим.\n",
        "\n",
        "5. В предыдущем уроке вы реализовали функцию обратного вызова, чтобы проверить функцию потерь и отменить тренировку, когда она достигнет определенной суммы. Посмотрите, сможете ли вы реализовать это здесь.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpYRidBXpBPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fdc8518-c859-4d09-adef-55624a377db8"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 3ms/step - loss: 0.1440 - accuracy: 0.9576\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0477 - accuracy: 0.9859\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0299 - accuracy: 0.9908\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0193 - accuracy: 0.9937\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0123 - accuracy: 0.9959\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0098 - accuracy: 0.9966\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0070 - accuracy: 0.9976\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0053 - accuracy: 0.9983\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0040 - accuracy: 0.9988\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9891\n",
            "0.9890999794006348\n"
          ]
        }
      ]
    }
  ]
}